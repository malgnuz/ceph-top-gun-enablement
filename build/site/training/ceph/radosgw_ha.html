<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Providing RadosGW HA :: Ceph Top Gun Enablement</title>
    <link rel="canonical" href="https://likid0.github.io/ceph-top-gun-enablement/training/ceph/radosgw_ha.html">
    <meta name="generator" content="Antora 3.0.1">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script>var uiRootPath = '../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://docs.ceph.com/en/latest/" target="_blank">
          <img src="../../_/img/header_logo_reverse.svg" height="48px" alt="Ceph">
      </a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Get Help</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/5" target="_blank">Ceph Documentation</a>
            <a class="navbar-item" href="https://bugzilla.redhat.com/describecomponents.cgi?product=Red%20Hat%20OpenShift%20Container%20Storage" target="_blank">Browse Bugs</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Improve Guides</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/likid0/ceph-top-gun-enablement/issues/new/choose" target="_blank">Open Issue</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Infos</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.redhat.com/en/blog/channel/red-hat-storage" target="_blank">Our Blog</a>
            <a class="navbar-item" href="https://www.youtube.com/channel/UCoyG8VyvB-XUxQl1mD3T3Gw" target="_blank">Youtube</a>
            <a class="navbar-item" href="https://docs.ceph.com/en/latest/" target="_blank">Ceph Storage Technology</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="training" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Ceph Top-Gun Enablement</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Lab Setup</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="opentlc_lab_env.html">Opentlc Lab Env</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Core Ceph</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_introduction.html">Ceph Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_architecture.html">Ceph Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cluster_partitioning.html">Ceph Cluster Partitioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_hardware.html">Ceph Hardware Recommendations</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_intro.html">Ceph Install Methods </a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephadm_intro.html">Cephadm Orchestrator</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deploy_basic.html">Deploy Ceph with Cephadm</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deploy_ui.html">Deploy Ceph from the UI</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_dashboard_metrics.html">Ceph Dashboard Management &amp; Metrics</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cli_intro.html">Ceph CLI basic commands</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_configuration.html">Ceph Configuration</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_pools.html">Ceph storage pools config</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_pgs.html">Ceph Health and PGs</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_bluestore.html">Ceph OSD Bluestore</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_recovery.html">Ceph OSD Failure/Recovery</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephx.html">Rados CephX Auth/AuthZ</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_version.html">What version of Ceph am I running?</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph-upgrades_cephadm.html">Upgrade Ceph with Cephadm</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_challenge.html">Challenge Ceph Deployment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph RADOS Block Device</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_intro.html">RADOS Block Device introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_export.html">RBD Import/Export</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_mirroring.html">RBD Mirroring</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_challenge.html">Challenge RBD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">CephFS Shared FileSystem</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephfs_intro.html">CephFS introduction &amp; Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephfs_advanced.html">CephFS Deep Dive</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephfs_challenge.html">Challenge Cephfs</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph RadosGW</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_intro.html">RGW Introduction &amp; Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_arch_deep_dive.html">RGW Deep Dive</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="radosgw_ha.html">RGW High Availability</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_ssl.html">RGW &amp; Ingress with SSL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_users_quotas.html">RGW Users &amp; Quotas</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_auth.html">RGW Auth &amp; Authz</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_object_versioning.html">RGW S3 Object Versioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_placement_and_storage_classes.html">RGW Placement &amp; Storage Classes</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_life_cycle_management.html">RGW Life Cycle Management</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_bucket_policy.html">RGW S3 Bucket Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_introduction.html">RGW Secure Token Service</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_bucket_role_policy.html">RGW Bucket vs Role Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_multisite.html">RGW Multisite Replication</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_cloudsync.html">RGW Object Cloud Transition</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_archive.html">RGW Archive Zone</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_presignedurl.html">RGW presigned URL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_opslog.html">RGW Opslog</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_bucket_notification.html">RGW bucket Notification</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_rgw_challenge.html">Challenge RGW</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Troubleshooting</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_logging.html">Troubleshooting Logs Debug Mode</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="trouble-shooting-nearfull-osds.html">Troubleshooting nearfull OSDs</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_bluestore.html">Troubleshooting Bluestore issues</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="trouble-shooting-large-omap-objects.html">Troubleshooting Large Omap Objects</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_break_and_fix.html">Troubleshooting Break &amp; Fix Hands-on</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Benchmarking</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_example.html">Setting the Inital Baseline</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_fio.html">Benchmarking Ceph block and File</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_object.html">Benchmarking Ceph Object(RGW)</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Stretched</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="rhcs-stretched-deploy.html">Ceph Stretch Mode</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Challenge Solutions</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_challenge_solution.html">Ceph Deployment Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_challenge_solution.html">Ceph RBD Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephfs_challenge_solution.html">Ceph CephFS Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_rgw_challenge_solution.html">Ceph RGW Solution</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Ceph Top-Gun Enablement</span>
    <span class="version">master</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Ceph Top-Gun Enablement</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">master</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Ceph Top-Gun Enablement</a></li>
    <li>Ceph RadosGW</li>
    <li><a href="radosgw_ha.html">RGW High Availability</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///antora/training/modules/ceph/pages/radosgw_ha.adoc">Edit this Page</a></div>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Providing RadosGW HA</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To avoid single points of failure in our Ceph RGW deployment, we need to provide
an S3/RGW endpoint that can tolerate the failure of one or more RGW services.
RGW is a restful HTTP endpoint that can be load-balanced for HA and increase
performance. There are some great examples of different RadosGW load-balancing mechanisms in this
<a href="https://github.com/mmgaggle/ceph-lb">repo</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_load_balancing_network_and_dns_considerations"><a class="anchor" href="#_load_balancing_network_and_dns_considerations"></a>2. Load-Balancing Network and DNS considerations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When deploying Ceph for a full blown Multi-Petabyte Object Storage Solution.
With requirements for High, Sustained throughputs Load-Balacing the RGW HTTP
endpoints with the help of BGP adn ECMP is a very good option</p>
</div>
<div class="paragraph">
<p>The keepalived + haproxy stack provided by the ingress service has it&#8217;s
limitations.</p>
</div>
<div class="sect2">
<h3 id="_network_fabric"><a class="anchor" href="#_network_fabric"></a>2.1. Network Fabric</h3>
<div class="paragraph">
<p>The network fabric at each site needs to provide sufficient bisectional bandwidth to support the declustered writing and reading of erasure coded object shards. It is recommended that each site’s network fabric have either zero (1:1), or very low oversubscription (eg. 2:1). The most common network topology for a site supporting a Ceph storage cluster is the spine and leaf topology. Path diversity and load sharing in the spine and leaf topology should be achieved by using multiple routes and equal cost multipath (ECMP). This allows the CRUSH algorithm the ability to spread erasure coded chunks or object replicas across network failure domains (osd-failure-domain=rack).</p>
</div>
</div>
<div class="sect2">
<h3 id="_intersite_networkingmulti_site"><a class="anchor" href="#_intersite_networkingmulti_site"></a>2.2. Intersite Networking(Multi-site)</h3>
<div class="paragraph">
<p>Networking between zones that participate in the same zone group will be utilized for asynchronous replication traffic. As such, the amount of intersite bandwidth must be equal to or greater than ingest throughput to prevent synchronization lag from growing and increasing data loss risks. Intersite networking will not be relied on for read traffic or reconstitution of objects because all objects are locally durable. Path diversity is recommended for intersite networking, and all intersite networks should be routed instead of switched to isolate failure domains. Ceph object gateway synchronization should be configured to use the HTTPS endpoint so replication traffic is encrypted with SSL/TLS.
Load Balancing</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/Load-Balance.png" alt="Load Balance Haproxy" width="840" height="680">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_local_haproxy_per_radosgw_service"><a class="anchor" href="#_local_haproxy_per_radosgw_service"></a>2.3. Local HAproxy per RadosGW service</h3>
<div class="paragraph">
<p>Ceph object gateway incorporates Civetweb, an embedded webserver. One challenge with Civetweb is that it requires a thread per TCP connection. We have found that running a local HAProxy instance in front of each Ceph object gateway to be beneficial because a smaller Ceph object gateway thread pool can service a larger number of connections. To keep connections between clients and HAProxy open, and close connections between HAproxy and the Ceph object gateway after each HTTP request we recommend the use of the http-server-close HAProxy configuration option.</p>
</div>
<div class="paragraph">
<p>Each storage host should also run a routing agent (eg. quagga) to advertise a route to the /32 network of the virtual IP address bound to the loopback interface which HAproxy is listening on. Upstream devices should use hardware-based equal cost multipath (ECMP) for load sharing and path diversity across storage hosts. If the routing agent loses adjacency with it’s upstream router due to software or hardware malfunction, the route will be withdrawn so the failed host will stop receiving traffic. Systemd can be employed to stop the quagga service if either the HAproxy or Ceph object gateway service crashes or stops.</p>
</div>
</div>
<div class="sect2">
<h3 id="_using_bgp_and_ecmp_for_load_balancing"><a class="anchor" href="#_using_bgp_and_ecmp_for_load_balancing"></a>2.4. Using BGP and ECMP for Load-Balancing</h3>
<div class="paragraph">
<p>This scenario requires upstream devices to be configured, and the required commands to configure will vary depending on the devices' network operating system. This makes this scenario more challenging to implement. On the other hand the resulting storage service is fault tolerant and active/active up to the ECMP width supported by upstream devices (commonly 32 or 64).</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ingress_service_for_load_balancing_rgw"><a class="anchor" href="#_ingress_service_for_load_balancing_rgw"></a>3. Ingress Service for Load Balancing RGW</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Since RHCS 5.1, Ceph provides a cephadm service called ingress that provides an
HA and load-balancing stack based on keepalive and haproxy.</p>
</div>
<div class="paragraph">
<p>The ingress service allows you to create a high-availability endpoint for RGW with a minimum set of configuration options. The orchestrator will deploy and manage a combination of haproxy and keepalived to balance the load on a floating virtual IP.
If SSL is used, then SSL must be configured and terminated by the ingress service, not RGW itself.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/ingress.png" alt="HAproxy Ingress Service" width="840" height="680">
</div>
</div>
<div class="paragraph">
<p>There are N hosts where the ingress service is deployed. Each host has a haproxy daemon and a keepalived daemon. A virtual IP is automatically configured on only one of these hosts simultaneously.</p>
</div>
<div class="paragraph">
<p>Each keepalived daemon checks every few seconds whether the haproxy daemon on the same host is responding. Keepalived will also check that the master keepalived daemon is running without problems. Suppose the “master” keepalived daemon or the active haproxy is not responding. In that case, one of the remaining keepalived daemons running in backup mode will be elected as master, and the virtual IP will be moved to that node.</p>
</div>
<div class="paragraph">
<p>The active haproxy acts like a load balancer, distributing all RGW requests between all the RGW daemons available.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploying_a_new_rgw_daemon"><a class="anchor" href="#_deploying_a_new_rgw_daemon"></a>4. Deploying a new RGW daemon</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Currently, in our lab, we have a single RGW service/daemon running. We need at
At least two RGW services configured with the same Real/Zonegroup/Zone and running
on different nodes to be able to provide HA.</p>
</div>
<div class="paragraph">
<p>So we will increase the count of RGW daemons for service multi.zone1
that was previously created to 2, and we will deploy the new daemon on
ceph-node02, just as a reminder, we can use the --dry-run parameter with cephadm
to see what actions will be taken:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">[root@ceph-node01 ~]# ceph orch apply rgw multi.zone1 --realm=multisite --zone=zone1 --placement="2 proxy01 ceph-node02" --port=8000  --dry-run
####################
SERVICESPEC PREVIEWS
####################
+---------+-----------------+-------------+-------------+
|SERVICE  |NAME             |ADD_TO       |REMOVE_FROM  |
+---------+-----------------+-------------+-------------+
|rgw      |rgw.multi.zone1  |ceph-node02  |             |
+---------+-----------------+-------------+-------------+
################
OSDSPEC PREVIEWS
################
+---------+------+------+------+----+-----+
|SERVICE  |NAME  |HOST  |DATA  |DB  |WAL  |
+---------+------+------+------+----+-----+
+---------+------+------+------+----+-----+
[root@ceph-node01 ~]# ceph orch apply rgw multi.zone1 --realm=multisite --zone=zone1 --placement="2 proxy01 ceph-node02" --port=8000
Scheduled rgw.multi.zone1 update...
[root@ceph-node01 ~]# ceph orch ps | grep rgw
rgw.multi.zone1.ceph-node02.lviwfb  ceph-node02  *:8000       running (3m)      3m ago   3m    45.7M        -  16.2.8-85.el8cp  b2c997ff1898  0e3521f3a162
rgw.multi.zone1.proxy01.mhawfj      proxy01      *:8000       running (30m)     4m ago  30m    61.9M        -  16.2.8-85.el8cp  b2c997ff1898  4de70934f04e</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploying_the_ingress_service"><a class="anchor" href="#_deploying_the_ingress_service"></a>5. Deploying the Ingress Service</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that we have two RGW instances running, we can deploy an ingress service to
provide HA and load-balancing of out S3 HTTP endpoint, we need a VIP for
Keepalived to load-balance, you can use <code>ip:</code> that has been pre-created, and it has
a DNS entry <code>s3zone1.example.com</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># host s3zone1.example.com
s3zone1.example.com has address 192.168.56.100

# cat &lt;&lt; EOF &gt;  rgw-ingress.yaml
service_type: ingress
service_id: multi.zone1
placement:
  hosts:
    - ceph-node02
    - proxy01
spec:
  backend_service: rgw.multi.zone1
  virtual_ip: 192.168.56.100/24
  frontend_port: 80
  monitor_port:  1967
EOF

# ceph orch apply -i rgw-ingress.yaml --dry-run
####################
SERVICESPEC PREVIEWS
####################
+---------+-----------------------------+-------------------------+-------------+
|SERVICE  |NAME                         |ADD_TO                   |REMOVE_FROM  |
+---------+-----------------------------+-------------------------+-------------+
|ingress  |ingress.ingress.multi.zone1  |ceph-node02 proxy01      |             |
+---------+-----------------------------+-------------------------+-------------+
# ceph orch apply -i rgw-ingress.yaml
Scheduled ingress.ingress.multi.zone1 update...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The services will take a while to get configured and running. We can check with
the ceph orch ps command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># ceph orch ps | grep multi\.zone1
haproxy.multi.zone1.ceph-node02.pmohrw     ceph-node02  *:80,1967    running (3m)      2m ago   3m    4080k        -  2.2.19-7ea3822    2e4cc4bf0734  c42086355034
haproxy.multi.zone1.proxy01.yrkhjo         proxy01      *:80,1967    running (2m)    103s ago   3m    3968k        -  2.2.19-7ea3822    2e4cc4bf0734  68a291f47547
keepalived.multi.zone1.ceph-node02.jiylee  ceph-node02               running (3m)      2m ago   3m    12.9M        -  2.1.5             a57b3797e25b  c008d1bdb07c
keepalived.multi.zone1.proxy01.aaitou      proxy01                   running (2m)    103s ago   2m    11.6M        -  2.1.5             a57b3797e25b  f9edc0155908
rgw.multi.zone1.ceph-node02.miiqve         ceph-node02  *:8000       running (7m)      2m ago   7m    56.1M        -  16.2.10-94.el8cp  34880245f74a  e08857213424
rgw.multi.zone1.proxy01.iqthgc             proxy01      *:8000       running (18m)   103s ago  81m    61.1M        -  16.2.10-94.el8cp  34880245f74a  3b54fc09986a</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can curl the VIP to check that it&#8217;s working</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl http://s3zone1.example.com
&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;ListAllMyBucketsResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/"&gt;&lt;Owner&gt;&lt;ID&gt;anonymous&lt;/ID&gt;&lt;DisplayName&gt;&lt;/DisplayName&gt;&lt;/Owner&gt;&lt;Buckets&gt;&lt;/Buckets&gt;&lt;/ListAllMyBucketsResult&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The haproxy configuration can be checked with the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># cephadm enter --name haproxy.ingress.multi.zone1.ceph-node02.vyqujm cat /var/lib/haproxy/haproxy.cfg
...
frontend frontend
    bind 192.168.56.100:80
    default_backend backend

backend backend
    option forwardfor
    balance static-rr
    option httpchk HEAD / HTTP/1.0
    server rgw.multi.zone1.ceph-node02.lviwfb 192.168.56.62:8000 check weight 100
    server rgw.multi.zone1.proxy01.mhawfj 192.168.56.24:8000 check weight 100</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Keepalived config can also be checked with the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># cephadm enter --name keepalived.ingress.multi.zone1.ceph-node02.yyelgh cat /etc/keepalived/keepalived.conf
...
vrrp_instance VI_0 {
  state MASTER
  priority 100
  interface eth0
  virtual_router_id 51
  advert_int 1
  authentication {
      auth_type PASS
      auth_pass ythfkjlbyqokmslqmuwx
  }
  unicast_src_ip 192.168.56.62
  unicast_peer {
    192.168.56.63
  }
  virtual_ipaddress {
    192.168.56.100/24 dev eth0
  }
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>NOTICE: One thing to take into account with Ingress service and keepalived is that it
uses the vrrp protocol, so vrrp communications need to be allowed in the
network.</p>
</div>
<div class="paragraph">
<p>Now that we have the Ingress service working and the Client requests are being
load-balanced between both RGW services, you can shutdown a node and check
with and s3 client that you can still interact with the S3 endpoint, uploading
some files, for example.</p>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
      <img src="../../_/img/header_logo.svg" alt="Ceph">
  </a>
</footer>
<script id="site-script" src="../../_/js/site.js" data-ui-root-path="../../_"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
