<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Cluster Health and PGs :: Ceph Top Gun Enablement</title>
    <link rel="canonical" href="https://likid0.github.io/ceph-top-gun-enablement/training/ceph/ceph_pgs.html">
    <meta name="generator" content="Antora 3.0.1">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script>var uiRootPath = '../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://docs.ceph.com/en/latest/" target="_blank">
          <img src="../../_/img/header_logo_reverse.svg" height="48px" alt="Ceph">
      </a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Get Help</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/5" target="_blank">Ceph Documentation</a>
            <a class="navbar-item" href="https://bugzilla.redhat.com/describecomponents.cgi?product=Red%20Hat%20OpenShift%20Container%20Storage" target="_blank">Browse Bugs</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Improve Guides</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/likid0/ceph-top-gun-enablement/issues/new/choose" target="_blank">Open Issue</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Infos</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.redhat.com/en/blog/channel/red-hat-storage" target="_blank">Our Blog</a>
            <a class="navbar-item" href="https://www.youtube.com/channel/UCoyG8VyvB-XUxQl1mD3T3Gw" target="_blank">Youtube</a>
            <a class="navbar-item" href="https://docs.ceph.com/en/latest/" target="_blank">Ceph Storage Technology</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="training" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Ceph Top-Gun Enablement</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Lab Setup</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="opentlc_lab_env.html">Opentlc Lab Env</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Core Ceph</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_introduction.html">Ceph Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_architecture.html">Ceph Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cluster_partitioning.html">Ceph Cluster Partitioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_hardware.html">Ceph Hardware Recommendations</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_intro.html">Ceph Install Methods </a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephadm_intro.html">Cephadm Orchestrator</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deploy_basic.html">Deploy Ceph with Cephadm</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deploy_ui.html">Deploy Ceph from the UI</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_dashboard_metrics.html">Ceph Dashboard Management &amp; Metrics</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cli_intro.html">Ceph CLI basic commands</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_configuration.html">Ceph Configuration</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_pools.html">Ceph storage pools config</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="ceph_pgs.html">Ceph Health and PGs</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_bluestore.html">Ceph OSD Bluestore</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_recovery.html">Ceph OSD Failure/Recovery</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephx.html">Rados CephX Auth/AuthZ</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_version.html">What version of Ceph am I running?</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph-upgrades_cephadm.html">Upgrade Ceph with Cephadm</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_challenge.html">Challenge Ceph Deployment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph RADOS Block Device</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_intro.html">RADOS Block Device introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_export.html">RBD Import/Export</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_mirroring.html">RBD Mirroring</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_challenge.html">Challenge RBD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">CephFS Shared FileSystem</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephfs_intro.html">CephFS introduction &amp; Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephfs_advanced.html">CephFS Deep Dive</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephfs_challenge.html">Challenge Cephfs</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph RadosGW</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_intro.html">RGW Introduction &amp; Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_arch_deep_dive.html">RGW Deep Dive</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_ha.html">RGW High Availability</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_ssl.html">RGW &amp; Ingress with SSL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_users_quotas.html">RGW Users &amp; Quotas</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_auth.html">RGW Auth &amp; Authz</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_object_versioning.html">RGW S3 Object Versioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_placement_and_storage_classes.html">RGW Placement &amp; Storage Classes</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_life_cycle_management.html">RGW Life Cycle Management</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_bucket_policy.html">RGW S3 Bucket Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_introduction.html">RGW Secure Token Service</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_bucket_role_policy.html">RGW Bucket vs Role Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_multisite.html">RGW Multisite Replication</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_cloudsync.html">RGW Object Cloud Transition</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_archive.html">RGW Archive Zone</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_presignedurl.html">RGW presigned URL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_opslog.html">RGW Opslog</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_bucket_notification.html">RGW bucket Notification</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_rgw_challenge.html">Challenge RGW</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Troubleshooting</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_logging.html">Troubleshooting Logs Debug Mode</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="trouble-shooting-nearfull-osds.html">Troubleshooting nearfull OSDs</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_bluestore.html">Troubleshooting Bluestore issues</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="trouble-shooting-large-omap-objects.html">Troubleshooting Large Omap Objects</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="troubleshooting_break_and_fix.html">Troubleshooting Break &amp; Fix Hands-on</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Benchmarking</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_example.html">Setting the Inital Baseline</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_fio.html">Benchmarking Ceph block and File</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_performance_object.html">Benchmarking Ceph Object(RGW)</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Stretched</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="rhcs-stretched-deploy.html">Ceph Stretch Mode</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Challenge Solutions</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_deployment_challenge_solution.html">Ceph Deployment Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cephrbd_challenge_solution.html">Ceph RBD Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_cephfs_challenge_solution.html">Ceph CephFS Solution</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="ceph_rgw_challenge_solution.html">Ceph RGW Solution</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Ceph Top-Gun Enablement</span>
    <span class="version">master</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Ceph Top-Gun Enablement</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">master</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Ceph Top-Gun Enablement</a></li>
    <li>Core Ceph</li>
    <li><a href="ceph_pgs.html">Ceph Health and PGs</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///antora/training/modules/ceph/pages/ceph_pgs.adoc">Edit this Page</a></div>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Cluster Health and PGs</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It&#8217;s important to monitor the state of PGs in a Ceph cluster to ensure that data is being properly replicated and that any issues with replication or placement are addressed in a timely manner.</p>
</div>
<div class="paragraph">
<p>Placement Group (PG) in Ceph is a group of objects that are stored together on the same set of storage devices, known as an OSD (Object Storage Device) cluster. The purpose of a PG is to manage data placement and replication within a Ceph storage cluster. Each object in the Ceph cluster is associated with a specific PG, and each PG is responsible for replicating and distributing its associated objects across multiple OSDs.</p>
</div>
<div class="paragraph">
<p>PGs are organized into pools, and each pool can have multiple PGs. The number of PGs in a pool is determined by the size of the pool and the desired level of data redundancy. When data is written to a Ceph cluster, it is striped across multiple PGs within a given pool, and each PG then replicates that data across multiple OSDs. This allows for data to be distributed across multiple devices and locations, providing high availability and fault tolerance.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_pg_states"><a class="anchor" href="#_pg_states"></a>2. PG states</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>"creating"</strong> - The PG is being created for the first time and is not yet ready for use.</p>
</li>
<li>
<p><strong>"active+clean"</strong> - The PG is fully functional and has all of its data replicated and available.</p>
</li>
<li>
<p><strong>"active+undersized"</strong> - The PG is fully functional but does not have enough replicas of its data.</p>
</li>
<li>
<p><strong>"active+degraded"</strong> - The PG is fully functional but one or more replicas of its data is missing or unavailable.</p>
</li>
<li>
<p><strong>"active+stale"</strong> - The PG is fully functional but one or more replicas of its data is stale and needs to be updated.</p>
</li>
<li>
<p><strong>"peering"</strong> - The PG is in the process of adjusting its placement and replication settings.</p>
</li>
<li>
<p><strong>"recovering"</strong> - The PG is in the process of recovering missing or unavailable data.</p>
</li>
<li>
<p><strong>"backfill"</strong> - The PG is in the process of adding new replicas to its data.</p>
</li>
<li>
<p><strong>"incomplete"</strong> - The PG does not have enough replicas to function and is waiting for additional nodes to join the cluster.</p>
</li>
<li>
<p><strong>"stale"</strong> - The PG is not currently in use and its data is being moved to other PGs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It&#8217;s important to monitor the state of PGs in a Ceph cluster to ensure that data is being properly replicated and that any issues with replication or placement are addressed in a timely manner. Some of the common tools used to monitor the PG states are ceph-pg-status, ceph-pg-dump, and ceph-pg-list.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_pgs_and_pools"><a class="anchor" href="#_pgs_and_pools"></a>3. PGs and Pools</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A pool is a logical collection of PGs, and it is used to manage the data replication and distribution for a specific set of objects. Each pool can have a different number of PGs, and a different replication factor, depending on the desired level of data redundancy. The number of PGs in a pool is determined by the size of the pool and the desired level of data redundancy.</p>
</div>
<div class="paragraph">
<p>In summary, PGs are responsible for managing the data placement and replication within a Ceph cluster, OSDs are the daemons that run on the storage nodes and are responsible for managing the data stored on those nodes, and pools are the logical collections of PGs that are used to manage the data replication and distribution for a specific set of objects. Each object in the Ceph cluster is associated with a specific PG, which is a part of a specific pool, and each PG is responsible for replicating and distributing its associated objects across multiple OSDs.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_pgs_and_peering"><a class="anchor" href="#_pgs_and_peering"></a>4. PGs and Peering</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Golden Rule is that no write operation to any PG is acknowledged to a client until it has been persisted by all members of the acting set for that PG. This means that if we can communicate with at least one member of each acting set since the last successful peering, someone will have a record of every (acknowledged) operation since the last successful peering. This means that it should be possible for the current primary to construct and disseminate a new authoritative history.</p>
</div>
<div class="paragraph">
<p>It is also important to appreciate the role of the OSD map (list of all known OSDs and their states, as well as some information about the placement groups) in the peering process:</p>
</div>
<div class="paragraph">
<p>When OSDs go up or down (or get added or removed) this has the potential to affect the active sets of many placement groups.</p>
</div>
<div class="paragraph">
<p>Before a primary successfully completes the peering process, the OSD map must reflect that the OSD was alive and well as of the first epoch in the current interval.</p>
</div>
<div class="paragraph">
<p>Changes can only be made after successful peering.</p>
</div>
<div class="paragraph">
<p>Thus, a new primary can use the latest OSD map along with a recent history of past maps to generate a set of past intervals to determine which OSDs must be consulted before we can successfully peer. The set of past intervals is bounded by last epoch started, the most recent past interval for which we know peering completed. The process by which an OSD discovers a PG exists in the first place is by exchanging PG info messages, so the OSD always has some lower bound on last epoch started.</p>
</div>
<div class="paragraph">
<p>The high level process is for the current PG primary to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>get a recent OSD map (to identify the members of the all interesting acting sets, and confirm that we are still the primary).</p>
</li>
<li>
<p>generate a list of past intervals since last epoch started. Consider the subset of those for which up_thru was greater than the first interval epoch by the last interval epoch’s OSD map; that is, the subset for which peering could have completed before the acting set changed to another set of OSDs.</p>
</li>
<li>
<p>Successful peering will require that we be able to contact at least one OSD from each of past interval’s acting set.</p>
</li>
<li>
<p>ask every node in that list for its PG info, which includes the most recent write made to the PG, and a value for last epoch started. If we learn about a last epoch started that is newer than our own, we can prune older past intervals and reduce the peer OSDs we need to contact.</p>
</li>
<li>
<p>if anyone else has (in its PG log) operations that I do not have, instruct them to send me the missing log entries so that the primary’s PG log is up to date (includes the newest write)..
for each member of the current acting set:</p>
<div class="ulist">
<ul>
<li>
<p>ask it for copies of all PG log entries since last epoch start so that I can verify that they agree with mine (or know what objects I will be telling it to delete).</p>
</li>
<li>
<p>If the cluster failed before an operation was persisted by all members of the acting set, and the subsequent peering did not remember that operation, and a node that did remember that operation later rejoined, its logs would record a different (divergent) history than the authoritative history that was reconstructed in the peering after the failure.</p>
</li>
<li>
<p>Since the divergent events were not recorded in other logs from that acting set, they were not acknowledged to the client, and there is no harm in discarding them (so that all OSDs agree on the authoritative history). But, we will have to instruct any OSD that stores data from a divergent update to delete the affected (and now deemed to be apocryphal) objects.</p>
</li>
<li>
<p>ask it for its missing set (object updates recorded in its PG log, but for which it does not have the new data). This is the list of objects that must be fully replicated before we can accept writes.</p>
</li>
</ul>
</div>
</li>
<li>
<p>at this point, the primary’s PG log contains an authoritative history of the placement group, and the OSD now has sufficient information to bring any other OSD in the acting set up to date.</p>
</li>
<li>
<p>if the primary’s up_thru value in the current OSD map is not greater than or equal to the first epoch in the current interval, send a request to the monitor to update it, and wait until receive an updated OSD map that reflects the change.</p>
</li>
<li>
<p>for each member of the current acting set:</p>
<div class="ulist">
<ul>
<li>
<p>send them log updates to bring their PG logs into agreement with my own (authoritative history) … which may involve deciding to delete divergent objects.</p>
</li>
<li>
<p>await acknowledgment that they have persisted the PG log entries.</p>
</li>
</ul>
</div>
</li>
<li>
<p>at this point all OSDs in the acting set agree on all of the meta-data, and would (in any future peering) return identical accounts of all updates.</p>
<div class="ulist">
<ul>
<li>
<p>start accepting client write operations (because we have unanimous agreement on the state of the objects into which those updates are being accepted). Note, however, that if a client tries to write to an object it will be promoted to the front of the recovery queue, and the write willy be applied after it is fully replicated to the current acting set.</p>
</li>
<li>
<p>update the last epoch started value in our local PG info, and instruct other active set OSDs to do the same.</p>
</li>
<li>
<p>start pulling object data updates that other OSDs have, but I do not. We may need to query OSDs from additional past intervals prior to last epoch started (the last time peering completed) and following last epoch clean (the last epoch that recovery completed) in order to find copies of all objects.</p>
</li>
<li>
<p>start pushing object data updates to other OSDs that do not yet have them.
We push these updates from the primary (rather than having the replicas pull them) because this allows the primary to ensure that a replica has the current contents before sending it an update write. It also makes it possible for a single read (from the primary) to be used to write the data to multiple replicas. If each replica did its own pulls, the data might have to be read multiple times.</p>
</li>
</ul>
</div>
</li>
<li>
<p>once all replicas store the all copies of all objects (that existed prior to the start of this epoch) we can update last epoch clean in the PG info, and we can dismiss all of the stray replicas, allowing them to delete their copies of objects for which they are no longer in the acting set.</p>
</li>
<li>
<p>We could not dismiss the strays prior to this because it was possible that one of those strays might hold the sole surviving copy of an old object (all of whose copies disappeared before they could be replicated on members of the current acting set).</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_increasing_the_number_of_pgs"><a class="anchor" href="#_increasing_the_number_of_pgs"></a>5. Increasing the number of PGs</h2>
<div class="sectionbody">
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This is the most intensive process that can be performed on a Ceph cluster, and can have drastic performance impact if not done in a slow and methodical fashion.
Once the data starts moving for a chunk of Placement Groups (PGs) ( in the increasing pgp_num section ), it cannot be stopped or reversed and must be allowed to complete.
It is advised that this process be performed off-hours, and all clients alerted to the potential performance impact well ahead of time.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Having proper Placement Group (PG) count is a critical part of ensuring top performance and best data distribution in your Ceph cluster.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The Ceph PG calc tool should be referenced for optimal values.</p>
</li>
<li>
<p>Care should be taken to maintain between 50 and 150 PGs per OSD ratio as detailed in the Ceph PG calc tool.</p>
</li>
<li>
<p>The current PG count per OSD can be viewed in the PGS column of the <code>ceph osd df tree</code> command.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># ceph osd df tree
ID  CLASS  WEIGHT   REWEIGHT  SIZE    RAW USE  DATA     OMAP  META    AVAIL   %USE  VAR   PGS  STATUS  TYPE NAME
-1         0.02939         -  30 GiB   76 MiB  1.8 MiB   0 B  74 MiB  30 GiB  0.25  1.00    -          root default
-3         0.02939         -  30 GiB   76 MiB  1.8 MiB   0 B  74 MiB  30 GiB  0.25  1.00    -              datacenter DC1
-2         0.00980         -  10 GiB   26 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  1.01    -                  host ceph-node01
 0    hdd  0.00980   1.00000  10 GiB   26 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  1.01  225      up              osd.0
-4         0.00980         -  10 GiB   25 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  0.99    -                  host ceph-node02
 1    hdd  0.00980   1.00000  10 GiB   25 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  0.99  225      up              osd.1
-5         0.00980         -  10 GiB   25 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  0.99    -                  host ceph-node03
 2    hdd  0.00980   1.00000  10 GiB   25 MiB  616 KiB   0 B  25 MiB  10 GiB  0.25  0.99  225      up              osd.2
                       TOTAL  30 GiB   76 MiB  1.8 MiB   0 B  74 MiB  30 GiB  0.25</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The only time increasing the PG count is required is if you expand your cluster with more OSDs, such that the ratio drops to or below 100 PGs per OSD ratio in your cluster, or if the initial PG count was not properly planned.</p>
</li>
<li>
<p>The PG count settings ( pg_num and pgp_num ) are configured per-pool.<code>pgp_num</code> is automatic in recent versions</p>
</li>
<li>
<p>Each pool which has a low PG count must be adjusted separately.</p>
</li>
<li>
<p>Due to the amount of data movementt, it is recommended to throttle the cluster&#8217;s backfill and recovery values to minimize client IO impact.</p>
</li>
<li>
<p>Disable scrub and deep scrub operations during the process to limit the potentially compounding IO load.</p>
</li>
<li>
<p>Due to the need to re-evaluate the contents of every PG in the pool, even with the backfill and recovery throttles in place, client IO can experience performance degradation.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_troubleshooting_pgs"><a class="anchor" href="#_troubleshooting_pgs"></a>6. Troubleshooting PGs</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Troubleshooting placement group (PG) issues in a Ceph cluster can be a complex process, but there are several tools and techniques that can help.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Monitor PG states: One of the first things to check when troubleshooting PG
issues is the state of the PGs in the cluster. The <code>ceph pg dump</code> command can
be used to view the state of all PGs in the cluster, and <code>ceph pg &lt;pgid&gt; state</code> can be used to view the state of a specific PG.</p>
</li>
<li>
<p>Check for Stuck PGs: If a PG is stuck in a particular state, it can cause
performance issues or data unavailability. Use the command <code>ceph pg dump
--format json-pretty</code> to check for stuck PGs.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># ceph pg dump_stuck stale
# ceph pg dump_stuck inactive
# ceph pg dump_stuck unclean</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>If you receive an active+clean+inconsistent state, this may happen due to an error during scrubbing. Identify the inconsistent placement group(s) by executing the following:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># ceph health detail
  HEALTH_ERR 1 pgs inconsistent; 2 scrub errors
  pg 0.6 is active+clean+inconsistent, acting [0,1,2]
  2 scrub errors

# rados list-inconsistent-pg rbd
  ["0.6"]

# rados list-inconsistent-obj 0.6 --format=json-pretty</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Query the cluster to determine exactly why the PG is marked down by executing the following: <code>ceph pg 0.5 query</code></p>
</li>
<li>
<p>Check for degraded objects: If a PG is in a degraded state, it means that one
or more replicas of the data is missing or unavailable. You can use the <code>ceph
object map &lt;objectname&gt;</code> command to check for degraded objects.</p>
</li>
<li>
<p>Check for failed OSDs: Failed OSDs can cause issues with data replication and
availability. Use the <code>ceph osd tree</code> command to check the status of all OSDs in the cluster</p>
</li>
<li>
<p>Check for slow OSDs: Slow OSDs can also cause issues with data replication and
availability. Use <code>ceph osd perf</code> command to check the performance of all OSDs in the cluster.</p>
</li>
<li>
<p>Check for errors in log files: Reviewing log files can often provide additional
information about the cause of a problem. The <code>ceph -s</code> command can be used to view the overall status of the cluster, including any errors or warnings that have been logged.</p>
</li>
<li>
<p>Check for network issues: Network issues can cause delays or disruptions in data replication and availability. To check for network issues, you can use tools like ping, traceroute, and netstat.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It&#8217;s important to identify and resolve PG issues as soon as possible to ensure that data is being properly replicated and that any issues with replication or placement are addressed in a timely manner.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cluster_health_status"><a class="anchor" href="#_cluster_health_status"></a>7. Cluster Health Status</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>HEALTH_OK:</strong> This indicates that the cluster is fully operational and all of its components are working as expected.</p>
</li>
<li>
<p><strong>HEALTH_WARN:</strong> This indicates that there may be some issues with the cluster, but they do not currently affect its overall functionality. For example, some OSDs may be down or some monitors may be unreachable, but the cluster is still able to function.</p>
</li>
<li>
<p><strong>HEALTH_ERR:</strong> This indicates that there are serious issues with the cluster that are affecting its functionality. For example, a critical number of OSDs may be down or there may be a problem with the metadata servers.</p>
</li>
<li>
<p><strong>HEALTH_FAILED:</strong> This indicates that the cluster is not operational and that data may be at risk. This can happen if all of the monitors are down or if there is a problem with the entire cluster that cannot be easily resolved.</p>
</li>
<li>
<p><strong>HEALTH_UNKNOWN:</strong> This indicates that the status of the cluster is unknown. This can happen if the cluster is not configured properly or if there is a problem with the communication between the different components.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It is important to monitor the health status of a Ceph cluster regularly, and to take appropriate action if the status changes to HEALTH_ERR or HEALTH_FAILED. This may involve adding or replacing hardware, adjusting the configuration of the cluster, or performing other types of maintenance to keep the cluster running smoothly.</p>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
      <img src="../../_/img/header_logo.svg" alt="Ceph">
  </a>
</footer>
<script id="site-script" src="../../_/js/site.js" data-ui-root-path="../../_"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
